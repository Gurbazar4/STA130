{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193b29f5",
   "metadata": {},
   "source": [
    "Q1. \n",
    "\n",
    "1) SLR uses one predictor and models a linear relationship between a predictor and the outcome. MLR on the other hand, uses multiple predictors. This allows for more complex modeling; relationships between multiple variables. MLR is better than SLR as it adds flexibility by taking into account additional variables, improving prediction accuracy.\n",
    "2) Using continuous variable in SLR models the outcome with a continuous variable, which implies a proportional relationship. However using indicator variable in SLR uses binary variables. This creates two levels in the outcome. Instead of a proportional relationship between the variable and the predictor, when using an indicator variable, a shift occurs in the intercept of the line.\n",
    "- outcome=beta_o+beta_1*continuousVariable\n",
    "- outcome=beta_0+beta_1*indicatorVariable\n",
    "3) With both continuous and indicator variables, the model ca adjust the outcome based on both numeric values and group members.\n",
    "4) It allows the model to represent different relationships between the continuous variable and the outcome depending on the indicator variable's value. This allows for modelling different slopes for different groups.\n",
    "- outcome=beta_0+beta_1*continuousVariable+beta_2*1(indicatorVariable)+beta3*(continuousVariable*1(indicatorVariable)))\n",
    "5) For a categorical variable with k levels, the model uses k-1 indicator variables, each representing a different category. The intercept represents the baseline group, while each coefficient represents the differece in outcome for each group compared/relative to the baseline.\n",
    "- outcome=beta_0+beta_1*1(categoricalVariable1)+beta_2*1(categoricalVariable2)+..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a552bc0",
   "metadata": {},
   "source": [
    "Q2. \n",
    "\n",
    "In this scenario, the outcome variable is the number of sales or the effectiveness of advertising. The predictor variable is the amount of money spend on TV and online advertising. If we assume there is no interaction between TV and online advertising expenditures the model would assume that the effect of each advertising medium is independent.\n",
    "- outcome=beta_0+beta_1*TV+beta_2*onlineAdvertising\n",
    "If we add an interaction effect between TV and online ad expenditures the model would become:\n",
    "- outcome=beta_0+beta_1*TV+beta_2*onlineAd+beta_3*(TV*onlineAd)\n",
    "1) Without interaction, the contribution of each advertising to sales will remain constant, regardless of spending on the other advertising. However with interaction, the contribution of one advertising changes based on the spending on the other. This shows more realistic outcomes.\n",
    "2) Using binary variables we can model high vs low budget levels, with the interaction term being a combined effect of both high budgets on sales.\n",
    "- Without interaction- outcome=beta_0+beta_1*1(TV_high)+beta_2*1(onlineAd_high)\n",
    "- With interaction- outcome=beta_0+beta_1*1(TV_high_+beta_2*1(onlineAd_high)+beta_3*(1(TV_high)*1(onlineAd_high))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af299",
   "metadata": {},
   "source": [
    "Q3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091eb2cd",
   "metadata": {},
   "source": [
    "Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6acea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fa942a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:35</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     02:28:35     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        02:28:35   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712215c2",
   "metadata": {},
   "source": [
    "The low R-squared value (17.6%) means that the model does not explain a large portion of the variability in the outcome. This could be due to unmeasured variables or noise in the data.\n",
    "However, the significant p-values for the coefficients suggest that the predictors have strong relationships with the outcome. These relationships are significant, but they don't account for much of the overall variability in the data.\n",
    "The predictors might be strongly related to the outcome in a specific context, but there may be other factors that are not included in the model that contribute to the remaining variability. So it's not really contradictory for the model to have a low R-squared value but still show significant predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b94a7",
   "metadata": {},
   "source": [
    "Here's a summary of our conversation:\n",
    "\n",
    "1. **Simple vs. Multiple Linear Regression**: We discussed the difference between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR). SLR has one predictor variable, while MLR has two or more. MLR provides greater flexibility, handling multiple factors, improving predictive power, adjusting for confounders, and capturing interactions.\n",
    "\n",
    "2. **Continuous vs. Indicator Variables in SLR**: We compared the use of continuous variables and indicator (binary) variables in SLR. A continuous variable produces a proportional change in the response variable, while an indicator variable shifts the intercept to reflect different group means.\n",
    "\n",
    "3. **Interaction Term between Continuous and Indicator Variables**: Adding an interaction term between a continuous variable and an indicator variable in MLR allows different slopes for the continuous variable across groups. This approach enables the model to fit unique slopes for each category represented by the indicator variable, enhancing flexibility.\n",
    "\n",
    "4. **Indicator Variables for Categorical Variables with Multiple Levels**: We discussed how to represent a categorical variable with multiple levels in MLR by creating \\( k - 1 \\) dummy variables (one-hot encoding). This structure gives each level a unique intercept and allows the model to fit parallel lines (shared slope) unless interaction terms are added for varying slopes across categories.\n",
    "\n",
    "This overview covers the distinctions and uses of continuous vs. indicator variables, interactions, and handling categorical data with multiple levels in regression models.\n",
    "\n",
    "https://chatgpt.com/share/6733d48e-a194-800b-b170-d1e9b99d9811"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a1e78",
   "metadata": {},
   "source": [
    "Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c9b729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dac385",
   "metadata": {},
   "source": [
    "The code splits the dataset into a 50-50 train-test split after filling any NaN values in the Type 2 column with None. The training set will be used to fit the models, while the test set will serve for out of sample testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46d1a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:41</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     02:28:41     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        02:28:41   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7253ec",
   "metadata": {},
   "source": [
    "The code fits a linear regression model using HP as the outcome and Attack and Defense as predictors. The model uses only the training set data, and evaluates the in-sample R-squared value. The last line of the code provides a summary of model 3's fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e6108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958532a1",
   "metadata": {},
   "source": [
    "The code calculates both in-sample and out-of-sample R-squared values for model 3. The in-sample R-squared value is the proportion of variance in HP. The out-of-sample R-squared value is the squared correlation between actual HP values in the test set and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d058f485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:48</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     02:28:48     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        02:28:48   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48dfadd",
   "metadata": {},
   "source": [
    "The code creates a more complex model compared to model 3 (The code in 2nd cell) with multiple predictors and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401b9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d601c",
   "metadata": {},
   "source": [
    "The code evaluates model 4's performance. Given model 4's complexity compared to model 3 the in-sample R-squared value is much higher. The out-of-sample R-squared value is lower than the in-sample R-squared value, which means the model likely overfits to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754887e",
   "metadata": {},
   "source": [
    "Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f61447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:55</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     02:28:55     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        02:28:55   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dbd16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:58</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     02:28:58     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        02:28:58   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff702426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001f1153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ad497",
   "metadata": {},
   "source": [
    "The model4 specification adds complex predictor interactions in the design matrix, which causes high multicollinearity. Multicollinearity occurs when predictors are highly correlated, which destabilizes coefficient estimates and limits the model's ability to generalize to new data. Even with centering and scaling, which normalizes predictors, the underlying correlation structure remains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa135f4",
   "metadata": {},
   "source": [
    "Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f369dac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:29:33</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     02:29:33     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        02:29:33   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc2b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c117026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:29:43</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     02:29:43     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        02:29:43   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eb100c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "201e4ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:30:06</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     02:30:06     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        02:30:06   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb918469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ced2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c648b883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd74704",
   "metadata": {},
   "source": [
    "Models 5 6 and 7 build up on each other to improve prediction accuracy and address multicollinearity. Model 5 introduces categorical predictors like Generation and Type, which adds interpretive power without excessive complexity. Model 6 narrows down predictors to only significant categories, which improves stability and out-of-sample performance by reducing redundancy. Model 7 then adds interactions among continuous predictors for deeper associations with HP. Finally, centering and scaling in Model 7 reduces the condition number significantly from 2.34 billion to 15.4, which enhances stability and generalizability by controlling multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a5f6b",
   "metadata": {},
   "source": [
    "Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad78c48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load California Housing dataset\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "california_df = california.frame\n",
    "\n",
    "# Define formula (replacing original variables with ones in California dataset)\n",
    "# Using 'MedHouseVal' as the target variable, with predictors 'AveRooms', 'AveOccup', and interaction terms\n",
    "linear_form = 'MedHouseVal ~ AveRooms * AveOccup + AveRooms * MedInc'\n",
    "\n",
    "# Initialize parameters for iterations\n",
    "reps = 100\n",
    "in_sample_Rsquared = np.zeros(reps)\n",
    "out_of_sample_Rsquared = np.zeros(reps)\n",
    "\n",
    "# Loop over 100 iterations of training/testing split and model fitting\n",
    "for i in range(reps):\n",
    "    # Split data into training and testing sets\n",
    "    california_train, california_test = train_test_split(california_df, train_size=0.7)\n",
    "    \n",
    "    # Fit model on training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=california_train).fit()\n",
    "    \n",
    "    # Store in-sample R-squared\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Store out-of-sample R-squared\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(\n",
    "        california_test.MedHouseVal, final_model_fit.predict(california_test)\n",
    "    )[0, 1]**2\n",
    "\n",
    "# Create DataFrame for R-squared values\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Plotting results\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", \n",
    "                 y=\"Out of Sample Performance (Rsquared)\",\n",
    "                 labels={\"In Sample Performance (Rsquared)\": \"In-sample R²\", \n",
    "                         \"Out of Sample Performance (Rsquared)\": \"Out-of-sample R²\"})\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], name=\"y=x\", line_shape='linear'))\n",
    "fig.update_layout(title=\"In-sample vs. Out-of-sample R-squared Performance over 100 Iterations\")\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03a2ce",
   "metadata": {},
   "source": [
    "I used the California Housing dataset, which includes housing information like room count, occupancy, and house values, making it suitable for linear regression tasks. The code performs 100 iterations to split the data, fit a linear model, and calculate both in-sample and out-of-sample R-squared values. The target variable is MedHouseVal which is median house value, and predictors include AveRooms , AveOccup, and MedInc, with interaction terms between AveRooms and the other predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3910",
   "metadata": {},
   "source": [
    "Q9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88c0e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8513f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e30b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3274f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f69404",
   "metadata": {},
   "source": [
    "These codes analyzes how well models trained on data from specific pokemon generations predict future generations' HP, which aims to assess the generalizability of models across different subsets of data. The steps include training models on Generation 1 data and testing their ability to predict HP for other generations, followed by training models on Generations 1 to 5 and testing on Generation 6. The process repeats for two models, model6 and model7. The in-sample R-squared values indicate how well the models fit the training data, while the out-of-sample R-squared values reveal how well the models generalize to unseen data. Low out-of-sample values suggest overfitting, meaning the models are too specific to the training data. This shows that models trained on multiple generations can capture broader relationships, improving generalizability and ensuring the model performs well across different generations. The results show that it is important to balance model complexity with generalizability for effective prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ca699",
   "metadata": {},
   "source": [
    "Here's a summary of our conversation:\n",
    "\n",
    "1. **Model Specification and Multicollinearity**:\n",
    "   - We discussed how complex model specifications, like in `model4`, create additional predictor variables in the design matrix, which can lead to high multicollinearity. This can reduce out-of-sample performance and generalizability, even with centering and scaling.\n",
    "\n",
    "2. **Developing Models 5, 6, and 7**:\n",
    "   - You aimed to improve on simpler models by extending `model3` and `model4`. Each subsequent model was designed to enhance predictive associations and address multicollinearity issues. We noted the reduced condition number in `model7` after centering and scaling, indicating that multicollinearity was less of a concern.\n",
    "\n",
    "3. **Iterative Model Training and Testing**:\n",
    "   - We modified code to use a different dataset, iteratively split data, fit models, and calculated in-sample and out-of-sample R-squared values over 100 iterations. This process helps highlight overfitting versus generalizability.\n",
    "\n",
    "4. **Evaluating Models Across Generations**:\n",
    "   - We reviewed code for training models on Pokémon Generation subsets to test their performance on data from other generations. Training on specific generations (e.g., Generation 1 or Generations 1-5) and testing on others allowed us to assess model generalizability, revealing insights about overfitting and model reliability across distinct subsets.\n",
    "\n",
    "Through each step, we focused on enhancing model generalizability, balancing complexity with predictive performance, and understanding the effects of multicollinearity and data variability across generations.\n",
    "\n",
    "https://chatgpt.com/share/67341ad2-a0f0-800b-9c82-caf11682f7aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b80cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
